


## 思路：

1. 访问http://qun.qq.com/member.html 来获取信息首先获取到所有加入群的群号，
2. 构造每个群页面url请求，发现群页面信息是通过Ajax加载的，执行script下拉页面操作得以请求到所有数据(没有想到其他的好法子==)，最后用BeautifulSoup解析网页保存数据
3. 使用pyecharts里Graph进行数据可视化

## 需要安装的模块

1. bs4
2. selenium
3. pyecharts
4. lxml

## 数据爬取:
```python
import time
import json
from selenium import webdriver
from selenium.webdriver.support.ui import WebDriverWait
from selenium.common.exceptions import TimeoutException
from selenium.webdriver.support import expected_conditions as EC
from selenium.webdriver.common.by import By
from bs4 import BeautifulSoup
options=webdriver.ChromeOptions()
browser = webdriver.Chrome(chrome_options=options)
#browser=webdriver.PhantomJS()
browser.set_page_load_timeout(3)
wait=WebDriverWait(browser,10)
mygroup=[]
othergroup=[]

qqnum=''
pwd=''

def get(URL):
    try:
        browser.get(URL)
    except TimeoutException as e:
        browser.execute_script('window.stop()')

def login():
    try:
        get('http://qun.qq.com/member.html')
        wait.until(EC.frame_to_be_available_and_switch_to_it((By.NAME,'login_frame')))
        wait.until(EC.element_to_be_clickable((By.ID,'switcher_plogin'))).click()
        browser.find_element_by_id('u').send_keys(qqnum)
        browser.find_element_by_id('p').send_keys(pwd)
        browser.find_element_by_id('login_button').click()
        wait.until(EC.presence_of_element_located((By.CSS_SELECTOR,'body > div.ui-dialog.on > div.body-content > div > div.input-tit > div.input-search > input')))
        print('登录成功!!')
    except TimeoutException:
        print('登录超时，正在尝试重新登录....')
        return login()

def get_group_list():
    htm=browser.page_source
    try:
        soup=BeautifulSoup(htm,'lxml')
        group_list=soup.find_all('ul',{'class':'my-group-list'})
        for flag,group in enumerate(group_list):
            if flag==0:
                #我管理的群
                li=group.find_all('li')
                for l in li:
                    mygroup.append((l['title'].replace('&nbsp;',''),l['data-id']))
            else:
                #我加入的群
                li=group.find_all('li')
                for l in li:
                    othergroup.append((l['title'].replace('&nbsp;',''),l['data-id']))
    except Exception as e:
        print(e)

def write_to_file(content):
    with open('result.txt','a',encoding='utf-8') as f:
        f.write(json.dumps(content,ensure_ascii=False)+'\n')
        f.close()

def parse_one(uri):
    try:
        browser.get(uri)
        browser.refresh()
        time.sleep(2)
        html=browser.page_source
        soup=BeautifulSoup(html,'lxml')
        groupMemberNum=int(soup.find('span',{'id':'groupMemberNum'}).get_text())
        #成员数大于500不进行爬取,可自行设置
        # if groupMemberNum>500:
        #     return None
        #加载ajax
        for i in range((groupMemberNum//20)+1):
            browser.execute_script('window.scrollTo(0, document.body.scrollHeight);')
            time.sleep(0.5)
        html=browser.page_source
        soup=BeautifulSoup(html,'lxml')
        groupTit=soup.find('span',{'id':'groupTit'}).get_text()
        print(groupTit,groupMemberNum)
        tb=soup.findAll('tbody',{'class':'list'})
        i=0
        datalist=[]
        for b in tb:
            tr=b.find_all('tr')
            for t in tr:
                data=t.find_all('td')
                r = data[2].a.i['class']
                rank = '管理员' if (len(r) == 2) else '成员'
                nick=data[2].span.get_text().strip()
                group_card=data[3].span.get_text().strip()
                qq=data[4].get_text().strip()
                sex=data[5].get_text().strip()
                qage=data[6].get_text()[:-1]
                start_time=data[7].get_text().strip()
                grade=data[8].get_text().strip()
                last_time=data[-1].get_text().strip() #if(data[-1].get_text().strip()) else 'xx'
                i+=1
                if i==1:
                    rank='群主'
                data=(i,rank,nick,group_card,qq,sex,qage,start_time,grade,last_time)
                datalist.append(data)
        data={groupTit:datalist}
        print(data,'\n')
        write_to_file(data)
    except Exception as e:
        print('解析错误!,正在尝试重新解析....',e)
        return parse_one(uri)
def main():
    login()
    get_group_list()
    count=0
    all_group=mygroup+othergroup
    print('my group:',mygroup)
    print('other group:',othergroup)
    for name,id in all_group:
        count+=1
        #防止爬取频率过高可自行设置
        if count%5==0:
            print('wait......')
            time.sleep(20)
        uri='http://qun.qq.com/member.html#gid={}'.format(id)
        parse_one(uri)
if __name__ == '__main__':
    main()
```

## 关系可视化
```py
from pyecharts import *
import json
m={}
with open('result.txt',encoding='utf-8') as f:
    for line in f.readlines():
        d=json.loads(line)
        m.update(d)

l=dict.fromkeys(m.keys(),[])
for x,v in enumerate(m.values()):
    data=[]
    for j in v:
        j=str(j[4])
        data.append(j)
    #超过100不显示,可自行设置
    if len(data)>100:
        data=data[:100]
    l[list(l.keys())[x]]=data

gnode=[]
onode=[]
for k in l.keys():
    gnode.append({'name':k})

t=[]
list(map(lambda x:t.extend(x),[i for i in l.values()]))
for i in set(t):
    onode.append({'name': i})

links=[]
for k,v in l.items():
    for x in v:
        links.append({'source': k, 'target': x})
nodes=gnode+onode
print(nodes)
print(links)
graph = Graph("关系图-力引导布局", width=3000, height=2000)
graph.add("", nodes, links,is_label_show=True,\
          graph_layout='force', graph_repulsion=200,line_color='black', \
        label_text_color=None)
graph.render('result.html')
```

## reply

1. 感谢提供如此优质的代码,以至于解决我想爬取QQ群成员而一直卡在登陆的问题上.
2. 爬取时我用selenium调用谷歌浏览器时报错,或许大家能碰到,我的解决办法是下载驱动:https://sites.google.com/a/chromium.org/chromedriver/downloads 放到与python.exe同级目录.这样就不会报错了.也不用设PATH了.
3. 查看爬取代码,有成员数大于500不进行爬取,想知道大概是什么原因不爬大于500人以上的呢?

把500人限制去掉爬取的时候大家把时间改得稍长一点。慢慢爬。。开始我没有改时间的时候被麻花痛发现了，搞得全部白色了。
后来改成这样就一直爬到现在还没爬死：
```py
        for i in range((groupMemberNum // 20) + 1):
            browser.execute_script('window.scrollTo(0, document.body.scrollHeight);')
            time.sleep(10.5)
```

另外:跑可视化时执行下面这段时报错: (楼主更新后问题已解决)

执行环境:python3.6

`l[list(l.keys()) <i>] = data`

提示内容:

`SyntaxError: invalid syntax`


## 问题

在 Python 下引用 Selenium 包开发时，刚开始测试 WebDriver 的功能直接就甩出了一个错误消息然后就中断了，错误消息：WebDriverException: 'chromedriver' executable needs to be in PATH. Please see https://sites.google.com/a/chromium.org/chromedriver/home

搜索并尝试一番后，顺利解决。方法如下：

安装 selenium 的 python 包之后，还要安装浏览器 driver

下载：https://sites.google.com/a/chromium.org/chromedriver/downloads

复制 chromedrive 文件到 Google Chrome 程序目录下 （放到与python.exe同级目录就不用设PATH了）